{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting codecs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement codecs (from versions: )\n",
      "No matching distribution found for codecs\n"
     ]
    }
   ],
   "source": [
    "# !pip install gensim\n",
    "# !pip install spacy\n",
    "!pip install codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unicode Handling\n",
    "from __future__ import unicode_literals\n",
    "import codecs\n",
    "\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "# spacy is used for pre-processing and traditional NLP\n",
    "import spacy\n",
    "from spacy.en import English\n",
    "\n",
    "# Gensim is used for LDA and word2vec\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '../../assets/dataset/captured-tweets.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = codecs.open(filename, 'r', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = [ tweet for tweet in codecs.open(filename, 'r', encoding=\"utf-8\") ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'LeadCorp Media @leadcorpmedia_  https://t.co/vRJG9Xnzw8\\n',\n",
       " u'RT mackdrama1017: ChieMoney use google and learn how to!\\n',\n",
       " u'@ShaffieWeru Morning bro here is my new video i need yr help im talented bt i lack a manager bro https://t.co/NTs3QM5YU5\\n',\n",
       " u'Google Play Gift Card Code\\n',\n",
       " u'Claim your Google Play Gift Card Code... https://t.co/ySYH1x5kQl #amazon #itunes #googl\\u2026 https://t.co/ayDI4X1FKO\\n',\n",
       " u'@rizsrug216 @tpaquette_IID Per https://t.co/jTlhLW8Ry5 (sorry), St. Devs for the sport come to:\\n',\n",
       " u'Baseball: .039\\n',\n",
       " u'Football: .125\\n',\n",
       " u'King of dark fantasy. Summon today. App Store: https://t.co/XeEuOEaXEG Google Play: https://t.co/vYQdbhrNEb #DarkSummoner\\n',\n",
       " u'King of dark fantasy. Summon today. App Store: https://t.co/1ce13KchYS Google Play: https://t.co/IkkkXuEu9Q #DarkSummoner\\n',\n",
       " u'@PolitiBunny @PhillipJHill89 you should go read a published article that Russell Simmons wrote him google it\\n',\n",
       " u\"I've entered to win a Google Nexus 6P from  !    https://t.co/4vFHfhaBey\\n\",\n",
       " u'@moniimamz I know! I saw it online like if u google the reviews for it! \\U0001f610\\n',\n",
       " u\"RT @kamcb29: I've entered to win a Google Nexus 6P from @MakeUseOf ! https://t.co/o30B9xG6Dx #giveaway #competition\\n\",\n",
       " u'Yayyyyy thanks for the follow @YeahhImAFangirl \\n',\n",
       " u'I LOVE your Google plus page with the other girls! \\U0001f49c\\U0001f606\\n',\n",
       " u\"After I've Google &amp; read a ton of articles on the same subject, I remember, I could've just searched YouTube for this shit \\U0001f620\\n\",\n",
       " u'Week 2 Power Rankings\\U0001f608: https://t.co/1xfRayMvpX\\n',\n",
       " u'RT @ShowerThoughtts: Apple has \"air\", Amazon has \"Fire\", Google has \"earth\", why doesn\\'t Microsoft have \"water\"?\\n',\n",
       " u\"-Looks up on Google 'MikexJeremy' secretly- &lt;33 ;) [@FnafSchimdt,@MikeSchmit10,]#SenpaiBot~\\n\",\n",
       " u'RT @_silentbent_: Go support @dadeputy single \"It\\'s Okay\" feat @jaesongreen on iTunes,Google\\u2026 https://t.co/WPc1jwFLs0\\n',\n",
       " u'Hi, Checkout this application. https://t.co/cpKpnbsTS7\\n',\n",
       " u'RT @glotevo: nerd ass girl  https://t.co/T7kDirxPEL\\n',\n",
       " u\"I'm playing My Singing Monsters. Check it out! https://t.co/JrWWtmojWC\\n\",\n",
       " u'Ever wanted to become a Google Small Business Advisor? Now you can! https://t.co/fcOkq6srSX\\n',\n",
       " u'Check out @GCloudAndroid. Never worry about losing your #Android device up to 10 GB Free to backup https://t.co/7eaqZEHAnI\\n',\n",
       " u'Top Android Apps (without all the games) revealed in hidden Google Play Store link -\\u2026 https://t.co/7ZSs9MkcLm #Android #India\\n',\n",
       " u'RT @clashbabes: Th8 50vs50! Come join the fun! https://t.co/mFgZlpU9M4\\n',\n",
       " u'https://t.co/0ElEQm917Q How To Increase Blog Traffic With Google Plus - #Blogging #SMM #SocialMedia https://t.co/UIcEYNJ4u2 :OfficialChat\\u2026\\n',\n",
       " u'RelNews: \\n',\n",
       " u\"                    Europe could produce a Facebook ' and the Google of healthcare\\n\",\n",
       " u' -The Daily Telegraph- https://t.co/C6J53DKUuU\\n',\n",
       " u'RelNews: \\n',\n",
       " u\"                    Europe could produce a Facebook \\\\' and the Google of healthcare\\n\",\n",
       " u' -The Daily Telegraph- https://t.co/C6J53DKUuU\\n']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[5:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the tweet data\n",
    "filename = '../../assets/dataset/captured-tweets.txt'\n",
    "tweets = []\n",
    "for tweet in codecs.open(filename, 'r', encoding=\"utf-8\"):\n",
    "    tweets.append(tweet)\n",
    "# Setting up spacy\n",
    "nlp_toolkit = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1a\n",
    "\n",
    "Write a function that can take a take a sentence parsed by `spacy` and identify if it mentions a company named 'Google'. Remember, `spacy` can find entities and codes them as `ORG` if they are a company. Look at the slides for class 13 if you need a hint:\n",
    "\n",
    "### Bonus (1b)\n",
    "\n",
    "Parameterize the company name so that the function works for any company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mentions_company(parsed):\n",
    "    for entity in parsed.ents:\n",
    "        if entity.text == \"Google\" and entity.label_ == 'ORG':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# 1b\n",
    "# better more generalized \n",
    "# sets a default don't have to worry about other applications that use the same method\n",
    "def mentions_company(parsed, company='Google'):\n",
    "    for entity in parsed.ents:\n",
    "        if entity.text == company and entity.label_ == 'ORG':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parsed = nlp_toolkit(\"Amber Google is a nice company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4905"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1c\n",
    "\n",
    "Write a function that can take a sentence parsed by `spacy` \n",
    "and return the verbs of the sentence (preferably lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_actions(parsed):\n",
    "    actions = []\n",
    "    for el in parsed:\n",
    "        if el.pos == spacy.parts_of_speech.VERB:\n",
    "            actions.append(el.text)\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from spacy.parts_of_speech import NOUN, VERB, PRON, ADV, ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "97\n",
      "82\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "print NOUN\n",
    "print VERB\n",
    "print ADJ\n",
    "print ADV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nerd ass girl  https://t.co/T7kDirxPEL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "firstTweet = tweets[4]\n",
    "print firstTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parsed = nlp_toolkit(firstTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sen = unicode(\"Hey whats up apples and peanut butter tasts good together\")\n",
    "parsed = nlp_toolkit(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for el in parsed.ents:\n",
    "    print x.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other POS\n",
      "other POS\n",
      "other POS\n",
      "other POS\n",
      "other POS\n",
      "other POS\n",
      "other POS\n",
      "other POS\n",
      "other POS\n",
      "other POS\n",
      "other POS\n"
     ]
    }
   ],
   "source": [
    "for el in parsed:\n",
    "    if el.pos == NOUN:\n",
    "        print \"noun yo\"\n",
    "    elif el.pos == VERB:\n",
    "        print \"verb right thurr\"\n",
    "    elif el.pos == PRON:\n",
    "        print \"pronoun\"\n",
    "    else:\n",
    "        print \"other POS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NOUN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-2da6714cc44b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mprint\u001b[0m \u001b[0mNOUN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'NOUN' is not defined"
     ]
    }
   ],
   "source": [
    "print NOUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1d\n",
    "For each tweet, parse it using spacy and print it out if the tweet has 'release' or 'announce' as a verb. You'll need to use your `mentions_company` and `get_actions` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet in tweets:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "    if mentions_company(parsed, 'Google'):\n",
    "        actions = get_actions(parsed)\n",
    "        if 'release' in actions or 'announce' in actions:\n",
    "            print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise 1e\n",
    "Write a function that identifies countries - HINT: the entity label for countries is GPE (or GeoPolitical Entity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mentions_country(parsed, country):\n",
    "    for toked in parsed:\n",
    "        print token.text\n",
    "#         every token has ents associated with it\n",
    "        if entity.text == country:\n",
    "#         if entity.text == country and entity.label_ == 'GPE':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1f\n",
    "\n",
    "Re-run (d) to find country tweets that discuss 'Iran' announcing or releasing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet in tweets:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "\n",
    "    if mentions_country(parsed, 'SpaceX'):\n",
    "        print \"here\"\n",
    "#         if token is Iran and is GPE the take the word parse again\n",
    "        actions = get_actions(parsed)\n",
    "#     function get_actions above which returns verbs\n",
    "        if 'release' in actions or 'announce' in actions:\n",
    "            print(tweet)\n",
    "#     else:\n",
    "#         print \"blaa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "New photos of SpaceX booster show sooty but undamaged rocket https://t.co/vWsRe3zir4 #tech #feedly"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Build a word2vec model of the tweets we have collected using gensim.\n",
    "First take the collection of tweets and tokenize them using spacy.\n",
    "\n",
    "### Exercise 2a:\n",
    "* Think about how this should be done. \n",
    "* Should you only use upper-case or lower-case? \n",
    "* Should you remove punctuations or symbols? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_split = [[x.text if x.pos != spacy.parts_of_speech.VERB else x.lemma_ \n",
    "                for x in nlp_toolkit(t)] for t in tweets]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2b:\n",
    "Build a word2vec model.\n",
    "Test the window size as well - this is how many surrounding words need to be used to model a word. What do you think is appropriate for Twitter? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(text_split, size=100, window=4, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2c:\n",
    "Test your word2vec model with a few similarity functions. \n",
    "* Find words similar to 'Syria'.\n",
    "* Find words similar to 'war'.\n",
    "* Find words similar to \"Iran\".\n",
    "* Find words similar to 'Verizon'. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['Syria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2d\n",
    "\n",
    "Adjust the choices in (b) and (c) as necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Filter tweets to those that mention 'Iran' or similar entities and 'war' or similar entities.\n",
    "* Do this using just spacy.\n",
    "* Do this using word2vec similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using spacy\n",
    "for tweet in tweets:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "    if mentions_country(parsed, 'Iran') or mentions_country(parsed, 'Iraq'): # ... you could add more\n",
    "        if 'attack' in get_actions(parsed):\n",
    "            print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using word2vec similarity scores\n",
    "for tweet in tweets[:200]:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "\n",
    "    similarity_to_iran = max([model.similarity('Iran', tok.text) for tok in parsed if tok.text in model.vocab], 0)\n",
    "    similarity_to_war = max([model.similarity('war', tok.text) for tok in parsed if tok.text in model.vocab], 0)\n",
    "    if similarity_to_iran > 0.9 and similarity_to_war > 0.9:\n",
    "#         print(similarity_to_iran, similarity_to_war, tweet)\n",
    "        print tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
